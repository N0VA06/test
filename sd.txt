
import os
import uuid
from typing import List, Dict, Any, Optional
import io
import tempfile
import traceback

import qdrant_client
from qdrant_client import QdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import Filter, FieldCondition, MatchValue

from langchain_community.vectorstores import Qdrant
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

# Added for PDF handling
import PyPDF2
from datetime import datetime

class VectorStoreManager:
    def __init__(
        self, 
        collection_name: str,
        embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2",
        qdrant_host: str = "localhost",
        qdrant_port: int = 6333
    ):
        self.collection_name = collection_name
        self.embedding_model_name = embedding_model_name
        self.qdrant_host = qdrant_host
        self.qdrant_port = qdrant_port
        
        # Initialize HuggingFace embeddings
        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)
        
        # Initialize Qdrant client
        self.client = QdrantClient(host=qdrant_host, port=qdrant_port)
        
        # Initialize vector store
        self.vector_store = None
        
    def connect_or_create_vector_store(self) -> None:
        """Connect to an existing vector store or create a new one if it doesn't exist."""
        collections = self.client.get_collections().collections
        collection_names = [collection.name for collection in collections]
        
        if self.collection_name in collection_names:
            print(f"Connecting to existing collection: {self.collection_name}")
            self.vector_store = Qdrant(
                client=self.client, 
                collection_name=self.collection_name, 
                embeddings=self.embeddings
            )
        else:
            print(f"Collection {self.collection_name} does not exist. Creating new collection.")
            self.create_vector_store()
            
    def create_vector_store(self) -> None:
        """Create a new vector store."""
        # Get vector size from the embedding model
        vector_size = len(self.embeddings.embed_query("Test query"))
        
        # Create collection
        self.client.create_collection(
            collection_name=self.collection_name,
            vectors_config=models.VectorParams(
                size=vector_size,
                distance=models.Distance.COSINE
            )
        )
        
        self.vector_store = Qdrant(
            client=self.client, 
            collection_name=self.collection_name, 
            embeddings=self.embeddings
        )
        print(f"Created new vector store: {self.collection_name}")
        
    def insert_documents(self, documents: List[str], metadata_list: Optional[List[Dict[str, Any]]] = None) -> List[str]:
        """Insert documents into the vector store with optional metadata."""
        if self.vector_store is None:
            self.connect_or_create_vector_store()
            
        if metadata_list is None:
            metadata_list = [{} for _ in documents]
            
        if len(documents) != len(metadata_list):
            raise ValueError("The number of documents must match the number of metadata dictionaries")
        
        # Debug info
        print(f"Attempting to insert {len(documents)} documents")
        for i, doc in enumerate(documents):
            print(f"Document {i+1} length: {len(doc)} characters")
            if len(doc) == 0:
                print("WARNING: Document is empty!")
        
        # Add unique IDs to metadata if not present and ensure all values are strings
        for meta in metadata_list:
            if "id" not in meta:
                meta["id"] = str(uuid.uuid4())
                
            # Ensure all metadata values are strings (Qdrant may have issues with some value types)
            for key in list(meta.keys()):
                if meta[key] is not None and not isinstance(meta[key], str):
                    meta[key] = str(meta[key])
        
        # Convert to LangChain Document objects
        langchain_docs = []
        for i, (doc_text, meta) in enumerate(zip(documents, metadata_list)):
            if not doc_text or len(doc_text.strip()) == 0:
                print(f"Skipping empty document with metadata: {meta}")
                continue
                
            langchain_docs.append(Document(
                page_content=doc_text,
                metadata=meta
            ))
        
        if not langchain_docs:
            print("No valid documents to add!")
            return []
        
        # Process documents with text splitter
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, 
            chunk_overlap=100,
            length_function=len,
        )
        
        split_docs = text_splitter.split_documents(langchain_docs)
        print(f"Split {len(langchain_docs)} documents into {len(split_docs)} chunks")
        
        # Debug: Check that metadata is preserved in splits
        print(f"Checking metadata in first chunk: {split_docs[0].metadata if split_docs else 'No chunks'}")
        
        if not split_docs:
            print("No document chunks created after splitting!")
            return []
        
        # Add documents to vector store
        try:
            ids = self.vector_store.add_documents(split_docs)
            print(f"Added {len(split_docs)} document chunks with {len(set([d.metadata['id'] for d in split_docs]))} unique document IDs")
            
            # Verify that documents were added by doing a direct check
            print("Verifying document insertion...")
            check = self.client.scroll(
                collection_name=self.collection_name,
                limit=5,
                with_payload=True
            )
            
            if isinstance(check, tuple):
                check_points = check[0]
            else:
                check_points = check.points
                
            print(f"Collection contains {len(check_points)} points")
            if check_points:
                print(f"Sample payload from inserted document: {check_points[0].payload if hasattr(check_points[0], 'payload') else 'No payload'}")
                
            return ids
        except Exception as e:
            print(f"Error adding documents to vector store: {e}")
            traceback.print_exc()
            return []
    def delete_by_filename(self, filename: str) -> None:
        """Delete all documents associated with a specific filename."""
        if self.vector_store is None:
            self.connect_or_create_vector_store()
        
        print(f"Attempting to delete all documents with filename: {filename}")
        
        try:
            # Try different possible paths for the filename field
            potential_paths = [
                "metadata.file_name",  # Nested in metadata
                "file_name",           # Direct in payload
                "payload.file_name",   # Another possible nesting
                "payload.metadata.file_name"  # Deep nesting
            ]
            
            total_deleted = 0
            
            for path in potential_paths:
                print(f"Trying to delete using path: {path}")
                
                # Create a filter for this path
                try:
                    filter_obj = Filter(
                        must=[
                            FieldCondition(
                                key=path,
                                match=MatchValue(value=filename)
                            )
                        ]
                    )
                    
                    # Try to find points with this filter
                    scroll_result = self.client.scroll(
                        collection_name=self.collection_name,
                        scroll_filter=filter_obj,
                        limit=10000,
                        with_payload=False  # Just get IDs
                    )
                    
                    # Extract points from result
                    if isinstance(scroll_result, tuple):
                        points = scroll_result[0]
                    else:
                        points = scroll_result.points
                    
                    if points and len(points) > 0:
                        point_ids = [point.id for point in points]
                        count = len(point_ids)
                        
                        # Delete these points
                        self.client.delete(
                            collection_name=self.collection_name,
                            points_selector=models.PointIdsList(
                                points=point_ids
                            )
                        )
                        
                        print(f"Successfully deleted {count} documents using path: {path}")
                        total_deleted += count
                        
                        # We found and deleted points, so we can stop trying other paths
                        if count > 0:
                            break
                        
                except Exception as path_error:
                    print(f"Error with path '{path}': {path_error}")
                    continue
            
            # If no points were deleted through the standard paths, try a different approach
            if total_deleted == 0:
                print("Standard paths didn't work. Trying a different approach...")
                
                # Get all points and manually filter them
                all_points = self.client.scroll(
                    collection_name=self.collection_name,
                    limit=10000,
                    with_payload=True
                )
                
                if isinstance(all_points, tuple):
                    points = all_points[0]
                else:
                    points = all_points.points
                
                # Collect IDs of points that have matching filename
                matching_ids = []
                
                for point in points:
                    payload = point.payload
                    
                    # Debug the structure of the first few points
                    if len(matching_ids) < 3:
                        print(f"Point ID: {point.id}")
                        print(f"Payload structure: {type(payload)}")
                        if hasattr(payload, "keys"):
                            print(f"Payload keys: {payload.keys()}")
                    
                    # Check if this point has the matching filename anywhere in its payload
                    point_matches = False
                    
                    if isinstance(payload, dict):
                        # Direct match
                        if 'file_name' in payload and payload['file_name'] == filename:
                            point_matches = True
                        
                        # Nested in metadata
                        elif 'metadata' in payload and isinstance(payload['metadata'], dict):
                            if 'file_name' in payload['metadata'] and payload['metadata']['file_name'] == filename:
                                point_matches = True
                    
                    if point_matches:
                        matching_ids.append(point.id)
                
                # If we found matching points, delete them
                if matching_ids:
                    self.client.delete(
                        collection_name=self.collection_name,
                        points_selector=models.PointIdsList(
                            points=matching_ids
                        )
                    )
                    
                    print(f"Successfully deleted {len(matching_ids)} documents using manual filtering")
                    total_deleted += len(matching_ids)
            
            # Final report
            if total_deleted > 0:
                print(f"Total documents deleted: {total_deleted}")
            else:
                print("No documents were found with the specified filename.")
            
        except Exception as e:
            print(f"Error deleting documents: {e}")
            traceback.print_exc()



    def list_all_filenames(self) -> List[str]:
        """List all unique filenames in the collection."""
        if self.vector_store is None:
            self.connect_or_create_vector_store()
            
        try:
            # Scroll through all documents
            search_result = self.client.scroll(
                collection_name=self.collection_name,
                limit=10000,
                with_payload=True,
                with_vectors=False
            )
            
            # In newer versions of Qdrant client, scroll returns a tuple (points, next_page_offset)
            if isinstance(search_result, tuple):
                points = search_result[0]  # First element is the list of points
            else:
                # For backwards compatibility with older client versions
                points = search_result.points
            
            # Extract unique filenames
            filenames = set()
            
            # Debug information
            print(f"Retrieved {len(points)} points from collection")
            
            for i, point in enumerate(points):
                # Debug the first few points to see their structure
                if i < 3:
                    print(f"Point {i} structure: {type(point)}")
                    print(f"Point {i} attributes: {dir(point)}")
                    if hasattr(point, 'payload'):
                        print(f"Point {i} payload: {point.payload}")
                        
                # Try different ways to access the payload based on Qdrant client version
                if hasattr(point, 'payload') and point.payload:
                    payload = point.payload
                elif hasattr(point, 'metadata') and point.metadata:
                    payload = point.metadata
                elif isinstance(point, dict) and 'payload' in point:
                    payload = point['payload']
                else:
                    # Skip if we can't find payload
                    continue
                    
                # Look for file_name in the payload
                if 'file_name' in payload:
                    filenames.add(payload['file_name'])
                elif 'metadata' in payload and 'file_name' in payload['metadata']:
                    filenames.add(payload['metadata']['file_name'])
                    
            return sorted(list(filenames))
        except Exception as e:
            print(f"Error listing filenames: {e}")
            traceback.print_exc()
            return []
            
    def search(self, query: str, k: int = 5, filter_metadata: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """Search for documents similar to the query."""
        if self.vector_store is None:
            self.connect_or_create_vector_store()
            
        # Convert filter_metadata to Qdrant filter if provided
        qdrant_filter = None
        if filter_metadata:
            filter_conditions = []
            for key, value in filter_metadata.items():
                filter_conditions.append(
                    FieldCondition(
                        key=key,
                        match=MatchValue(value=value)
                    )
                )
                
            qdrant_filter = Filter(
                must=filter_conditions
            )
        
        try:
            # Perform search
            results = self.vector_store.similarity_search_with_score(
                query=query,
                k=k,
                filter=qdrant_filter
            )
            
            # Format results
            formatted_results = []
            for doc, score in results:
                formatted_results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "score": score
                })
                
            return formatted_results
        except Exception as e:
            print(f"Error during search: {e}")
            traceback.print_exc()
            
            # Let's try a direct scroll of the collection to see what's there
            print("\nAttempting direct collection scroll to debug:")
            try:
                scroll_result = self.client.scroll(
                    collection_name=self.collection_name,
                    limit=5,
                    with_payload=True
                )
                
                if isinstance(scroll_result, tuple):
                    points = scroll_result[0]
                else:
                    points = scroll_result.points
                    
                print(f"Retrieved {len(points)} points directly from collection")
                
                for i, point in enumerate(points):
                    print(f"Point {i} type: {type(point)}")
                    if hasattr(point, 'payload'):
                        print(f"Point {i} payload: {point.payload}")
                        
            except Exception as inner_e:
                print(f"Error during debug scroll: {inner_e}")
                
            return []

def extract_pdf_metadata_and_text(file_path: str) -> tuple:
    """Extract metadata and text from a PDF file."""
    try:
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            
            # Extract metadata
            metadata = {}
            info = pdf_reader.metadata
            
            if info:
                for key in info:
                    # Clean up the key name
                    clean_key = key
                    if key.startswith('/'):
                        clean_key = key[1:]
                    
                    # Add to metadata dictionary, converting to string
                    if info[key]:
                        metadata[clean_key] = str(info[key])
            
            # Add additional metadata
            metadata['page_count'] = len(pdf_reader.pages)
            metadata['file_name'] = os.path.basename(file_path)
            metadata['file_path'] = file_path
            metadata['import_date'] = datetime.now().isoformat()
            
            # Extract text
            text = ""
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n\n"
            
            print(f"Extracted {len(text)} characters from PDF")
            if len(text) == 0:
                print("WARNING: No text extracted from PDF. The PDF might be scanned or image-based.")
            
            return text, metadata
            
    except Exception as e:
        print(f"Error extracting PDF content: {e}")
        traceback.print_exc()
        return "", {"error": str(e), "file_path": file_path}

def extract_text_file_content(file_path: str) -> tuple:
    """Extract content from a text file and generate basic metadata."""
    encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
    
    for encoding in encodings_to_try:
        try:
            with open(file_path, 'r', encoding=encoding) as file:
                content = file.read()
            
            print(f"Successfully read file using {encoding} encoding. Content length: {len(content)} characters")
            
            # Create basic metadata
            metadata = {
                'file_name': os.path.basename(file_path),
                'file_path': file_path,
                'encoding': encoding,
                'import_date': datetime.now().isoformat(),
                'file_size_bytes': os.path.getsize(file_path)
            }
            
            return content, metadata
        
        except UnicodeDecodeError:
            continue
        except Exception as e:
            print(f"Error reading file with {encoding} encoding: {e}")
    
    # Try binary mode as a last resort
    try:
        with open(file_path, 'rb') as file:
            binary_content = file.read()
            content = binary_content.decode('latin-1', errors='replace')  # Use replace mode to handle any errors
            
        print(f"Read file in binary mode and decoded with latin-1 (replace mode). Content length: {len(content)} characters")
        
        metadata = {
            'file_name': os.path.basename(file_path),
            'file_path': file_path,
            'encoding': 'binary/latin-1',
            'import_date': datetime.now().isoformat(),
            'file_size_bytes': os.path.getsize(file_path)
        }
        
        return content, metadata
    except Exception as e:
        print(f"Error reading file in binary mode: {e}")
        traceback.print_exc()
    
    return "", {"error": "Could not decode file with any supported encoding", "file_path": file_path}

def main():
    print("Vector Store Management System")
    print("==============================")
    
    # Get collection name
    collection_name = input("Enter the name of the vector store collection: ")
    
    # Create vector store manager
    manager = VectorStoreManager(collection_name=collection_name)
    
    # Check if collection exists
    collections = manager.client.get_collections().collections
    collection_names = [collection.name for collection in collections]
    
    if collection_name in collection_names:
        print(f"Collection '{collection_name}' exists.")
        manager.connect_or_create_vector_store()
    else:
        create_new = input(f"Collection '{collection_name}' does not exist. Create it? (y/n): ")
        if create_new.lower() == 'y':
            manager.create_vector_store()
        else:
            print("Exiting.")
            return
    
    while True:
        print("\nOptions:")
        print("1. Insert documents")
        print("2. Delete documents by metadata")
        print("3. Delete documents by filename")
        print("4. List all filenames")
        print("5. Search documents")
        print("6. List collections")
        print("7. Exit")
        
        choice = input("Enter your choice (1-7): ")
        
        if choice == '1':
            # Insert documents
            file_path = input("Enter the path to the document file: ")
            
            if not os.path.exists(file_path):
                print(f"Error: File '{file_path}' does not exist.")
                continue
                
            try:
                # Determine file type and extract content appropriately
                file_extension = os.path.splitext(file_path)[1].lower()
                
                if file_extension == '.pdf':
                    print("Processing PDF file...")
                    content, extracted_metadata = extract_pdf_metadata_and_text(file_path)
                else:
                    # Assume it's a text file
                    print("Processing text file...")
                    content, extracted_metadata = extract_text_file_content(file_path)
                
                if not content:
                    print("Error: Could not extract content from the file.")
                    
                    # Ask if user wants to continue with empty content
                    if input("Do you want to continue with empty content? (y/n): ").lower() != 'y':
                        continue
                
                # Display extracted metadata
                print("\nExtracted metadata:")
                for key, value in extracted_metadata.items():
                    print(f"  {key}: {value}")
                
                # Ask if user wants to modify metadata
                modify_metadata = input("\nDo you want to modify or add to this metadata? (y/n): ")
                if modify_metadata.lower() == 'y':
                    print("Enter additional metadata key-value pairs (empty key to finish):")
                    while True:
                        key = input("Metadata key (or empty to finish): ")
                        if not key:
                            break
                        value = input(f"Value for {key}: ")
                        extracted_metadata[key] = value
                
                # Insert the document with metadata
                ids = manager.insert_documents([content], [extracted_metadata])
                
                if ids and len(ids) > 0:
                    print(f"Document inserted successfully with {len(ids)} chunks.")
                else:
                    print("Failed to insert document. No document chunks were created.")
                
            except Exception as e:
                print(f"Error inserting document: {e}")
                traceback.print_exc()
                
        elif choice == '2':
            # Delete documents by metadata
            metadata_filter = {}
            print("Enter metadata filter for deletion (empty key to finish):")
            while True:
                key = input("Metadata key (or empty to finish): ")
                if not key:
                    break
                value = input(f"Value for {key}: ")
                metadata_filter[key] = value
            
            if metadata_filter:
                confirm = input(f"Are you sure you want to delete documents with metadata {metadata_filter}? (y/n): ")
                if confirm.lower() == 'y':
                    manager.delete_by_metadata(metadata_filter)
                else:
                    print("Deletion cancelled.")
            else:
                print("No metadata filter provided. Deletion cancelled.")
                
        elif choice == '3':
            # Delete documents by filename
            # First, list available filenames
            filenames = manager.list_all_filenames()
            
            if not filenames:
                print("No documents found in the collection.")
                continue
                
            print("\nAvailable filenames:")
            for i, filename in enumerate(filenames):
                print(f"{i+1}. {filename}")
                
            # Ask user to select a filename
            selection = input("\nEnter the number of the file to delete, or type the filename directly: ")
            
            try:
                # Check if input is a number
                idx = int(selection) - 1
                if 0 <= idx < len(filenames):
                    filename = filenames[idx]
                else:
                    print("Invalid selection.")
                    continue
            except ValueError:
                # Input is a string, use it directly as filename
                filename = selection
                
            # Confirm deletion
            confirm = input(f"Are you sure you want to delete all documents associated with '{filename}'? (y/n): ")
            if confirm.lower() == 'y':
                manager.delete_by_filename(filename)
            else:
                print("Deletion cancelled.")
                
        elif choice == '4':
            # List all filenames
            filenames = manager.list_all_filenames()
            
            if filenames:
                print("\nFiles in the vector store:")
                for i, filename in enumerate(filenames):
                    print(f"{i+1}. {filename}")
            else:
                print("\nNo files found in the vector store.")
                
        elif choice == '5':
            # Search documents
            query = input("Enter your search query: ")
            k = int(input("Number of results to return (default 5): ") or "5")
            
            # Option to filter by filename
            use_filename_filter = input("Do you want to filter search by filename? (y/n): ")
            filter_metadata = None
            
            if use_filename_filter.lower() == 'y':
                filenames = manager.list_all_filenames()
                
                if not filenames:
                    print("No documents found in the collection.")
                    continue
                    
                print("\nAvailable filenames:")
                for i, filename in enumerate(filenames):
                    print(f"{i+1}. {filename}")
                    
                # Ask user to select a filename
                selection = input("\nEnter the number of the file to search in, or type the filename directly: ")
                
                try:
                    # Check if input is a number
                    idx = int(selection) - 1
                    if 0 <= idx < len(filenames):
                        filename = filenames[idx]
                    else:
                        print("Invalid selection.")
                        continue
                except ValueError:
                    # Input is a string, use it directly as filename
                    filename = selection
                    
                filter_metadata = {"file_name": filename}
            else:
                # Ask if user wants to filter by other metadata
                use_filter = input("Do you want to filter search by other metadata? (y/n): ")
                if use_filter.lower() == 'y':
                    filter_metadata = {}
                    print("Enter metadata filter for search (empty key to finish):")
                    while True:
                        key = input("Metadata key (or empty to finish): ")
                        if not key:
                            break
                        value = input(f"Value for {key}: ")
                        filter_metadata[key] = value
            
            results = manager.search(query, k, filter_metadata)
            
            print(f"\nFound {len(results)} results:")
            for i, result in enumerate(results):
                print(f"\nResult {i+1} (Score: {result['score']:.4f}):")
                print(f"Content: {result['content'][:200]}..." if len(result['content']) > 200 else f"Content: {result['content']}")
                print(f"Metadata: {result['metadata']}")
                
        elif choice == '6':
            # List collections
            collections = manager.client.get_collections().collections
            
            if collections:
                print("\nAvailable collections:")
                for i, collection in enumerate(collections):
                    print(f"{i+1}. {collection.name}")
            else:
                print("\nNo collections found.")
                
        elif choice == '7':
            # Exit
            print("Exiting. Goodbye!")
            break
            
        else:
            print("Invalid choice. Please try again.")

if __name__ == "__main__":
    main()
