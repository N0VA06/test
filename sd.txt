import os
import numpy as np
from dotenv import load_dotenv
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct
from transformers import AutoTokenizer, AutoModel
import torch

# Load environment variables
load_dotenv()

# Qdrant connection details
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

# Collection name
COLLECTION_NAME = "document_collection"

# Hugging Face model settings
# Using all-MiniLM-L6-v2 which is a good balance of performance and speed (384 dimensions)
HF_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"

def setup_collection(client, vector_size=384):
    """
    Create or recreate the collection with the specified vector size
    """
    # Check if collection exists
    if client.collection_exists(COLLECTION_NAME):
        print(f"Collection '{COLLECTION_NAME}' already exists. Recreate? (y/n)")
        choice = input().lower()
        if choice == 'y':
            client.delete_collection(COLLECTION_NAME)
            print(f"Collection '{COLLECTION_NAME}' deleted.")
        else:
            print(f"Using existing collection '{COLLECTION_NAME}'.")
            return
    
    # Create collection with the 384 dimensions for the Hugging Face model
    client.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
    )
    print(f"Collection '{COLLECTION_NAME}' created with vector size {vector_size}.")

# Mean Pooling function to convert token embeddings to sentence embedding
def mean_pooling(model_output, attention_mask):
    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

class HuggingFaceEmbedder:
    def __init__(self, model_name):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        # Move model to GPU if available
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        print(f"Using device: {self.device}")
    
    def generate_embeddings(self, texts):
        """
        Generate embeddings for a list of texts using the Hugging Face model
        """
        # Tokenize sentences
        encoded_input = self.tokenizer(
            texts, 
            padding=True, 
            truncation=True, 
            max_length=512, 
            return_tensors='pt'
        ).to(self.device)
        
        # Compute token embeddings
        with torch.no_grad():
            model_output = self.model(**encoded_input)
        
        # Perform pooling
        embeddings = mean_pooling(model_output, encoded_input['attention_mask'])
        
        # Normalize embeddings
        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
        
        # Convert to numpy and then to list format
        return embeddings.cpu().numpy().tolist()

def search_documents(query_text, embedder, limit=5):
    """
    Search documents in Qdrant that are relevant to the query
    """
    try:
        # Initialize Qdrant client
        qdrant_client = QdrantClient(
            url=QDRANT_URL,
            api_key=QDRANT_API_KEY
        )
        
        # Get collection info to check vector dimensions
        collection_info = qdrant_client.get_collection(COLLECTION_NAME)
        expected_dim = collection_info.config.params.vectors.size
        print(f"Qdrant collection expects {expected_dim}-dimensional vectors")
        
        # Generate embedding for the query using Hugging Face model
        query_vector = embedder.generate_embeddings([query_text])[0]
        print(f"Generated embedding with {len(query_vector)} dimensions")
        
        # Handle dimension mismatch if necessary
        if len(query_vector) != expected_dim:
            print(f"Resizing vector from {len(query_vector)} to {expected_dim} dimensions")
            if len(query_vector) > expected_dim:
                query_vector = query_vector[:expected_dim]
            else:
                query_vector = query_vector + [0] * (expected_dim - len(query_vector))
        
        # Search Qdrant for similar documents
        search_results = qdrant_client.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_vector,
            limit=limit,
            with_payload=True,
            score_threshold=0.6  # Adjusted threshold for Hugging Face models
        )
        
        # Format and return results
        results = []
        for result in search_results:
            results.append({
                "document": result.payload.get("text", "No text available"),
                "metadata": {
                    key: value for key, value in result.payload.items() 
                    if key != "text"
                },
                "score": result.score
            })
        
        return results
    
    except Exception as e:
        print(f"Error searching documents: {e}")
        import traceback
        traceback.print_exc()
        return []

def process_pdf_with_hf_embeddings(file_path, embedder):
    """Process a single PDF and upload embeddings to Qdrant"""
    try:
        import PyPDF2
        
        # Initialize Qdrant client
        qdrant_client = QdrantClient(
            url=QDRANT_URL,
            api_key=QDRANT_API_KEY
        )
        
        # Create collection if it doesn't exist
        setup_collection(qdrant_client)
        
        # Extract text from PDF
        with open(file_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            total_pages = len(reader.pages)
            print(f"Processing PDF: {os.path.basename(file_path)} - {total_pages} pages")
            
            # Extract text by pages
            chunks = []
            for i, page in enumerate(reader.pages):
                page_text = page.extract_text()
                if page_text and len(page_text.strip()) > 0:
                    chunks.append({
                        "text": f"Page {i+1}: {page_text}",
                        "metadata": {
                            "source": file_path,
                            "page": i+1,
                            "total_pages": total_pages,
                            "filename": os.path.basename(file_path)
                        }
                    })
            
            if not chunks:
                print(f"No text extracted from {file_path}")
                return
            
            print(f"Extracted {len(chunks)} text chunks from PDF")
            
            # Generate embeddings in batches
            BATCH_SIZE = 8  # Smaller batch size for memory efficiency
            
            for i in range(0, len(chunks), BATCH_SIZE):
                batch = chunks[i:i+BATCH_SIZE]
                texts = [item["text"] for item in batch]
                
                print(f"Generating embeddings for batch {i//BATCH_SIZE + 1}/{(len(chunks)-1)//BATCH_SIZE + 1}")
                batch_embeddings = embedder.generate_embeddings(texts)
                
                # Prepare points for Qdrant
                points = []
                for j, (item, embedding) in enumerate(zip(batch, batch_embeddings)):
                    # Generate a stable ID based on content
                    point_id = f"{os.path.basename(file_path)}-page-{item['metadata']['page']}"
                    point_id = point_id.encode('utf-8')
                    import hashlib
                    point_id_hash = hashlib.md5(point_id).hexdigest()
                    
                    points.append(PointStruct(
                        id=point_id_hash,
                        vector=embedding,
                        payload={
                            "text": item["text"],
                            **item["metadata"]
                        }
                    ))
                
                # Upload to Qdrant
                try:
                    qdrant_client.upsert(
                        collection_name=COLLECTION_NAME,
                        points=points
                    )
                    print(f"Uploaded batch {i//BATCH_SIZE + 1}, {len(points)} chunks to Qdrant")
                except Exception as e:
                    print(f"Error uploading batch to Qdrant: {e}")
        
        # Get collection info
        collection_info = qdrant_client.get_collection(COLLECTION_NAME)
        print(f"\nUpload complete. Collection '{COLLECTION_NAME}' now has {collection_info.vectors_count} vectors.")
            
    except Exception as e:
        print(f"Error processing PDF: {e}")
        import traceback
        traceback.print_exc()

def main():
    print("Select an option:")
    print("1. Upload a PDF document")
    print("2. Search documents")
    choice = input("Enter choice (1 or 2): ")
    
    # Initialize the embedder
    print(f"Loading Hugging Face model: {HF_MODEL_NAME}...")
    embedder = HuggingFaceEmbedder(HF_MODEL_NAME)
    print("Model loaded successfully.")
    
    if choice == '1':
        # Option to upload a PDF
        pdf_path = input("Enter the path to the PDF file: ")
        if os.path.exists(pdf_path) and pdf_path.lower().endswith('.pdf'):
            process_pdf_with_hf_embeddings(pdf_path, embedder)
        else:
            print("Invalid PDF path or file is not a PDF.")
    
    elif choice == '2':
        # Option to search
        user_query = input("Enter your query: ")
        print(f"\nSearching for documents relevant to: '{user_query}'")
        
        results = search_documents(user_query, embedder)
        
        if not results:
            print("No relevant documents found.")
        else:
            print("\nFound the following relevant documents:")
            for i, result in enumerate(results, 1):
                print(f"\n--- Result {i} (Relevance Score: {result['score']:.4f}) ---")
                print(f"Document: {result['document'][:200]}...")
                if result['metadata']:
                    print("Metadata:")
                    for key, value in result['metadata'].items():
                        if key != "text":
                            print(f"  - {key}: {value}")
    
    else:
        print("Invalid choice.")

if __name__ == "__main__":
    # Install required packages if missing
    try:
        import transformers
    except ImportError:
        print("Installing required packages...")
        import subprocess
        subprocess.check_call(["pip", "install", "transformers", "torch", "sentence-transformers", "PyPDF2"])
        print("Packages installed.")
    
    main()
